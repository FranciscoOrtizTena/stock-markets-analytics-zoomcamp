{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f38a1046",
   "metadata": {},
   "source": [
    "## Module 1 Homework (2025 cohort)\n",
    "\n",
    "In this homework, we're going to download finance data from various sources and make simple calculations or analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c377b71",
   "metadata": {},
   "source": [
    "### Question 1: [Index] S&P 500 Stocks Added to the Index\n",
    "\n",
    "**Which year had the highest number of additions?**\n",
    "\n",
    "Using the list of S&P 500 companies from Wikipedia's [S&P 500 companies page](https://en.wikipedia.org/wiki/List_of_S%26P_500_companies), download the data including the year each company was added to the index.\n",
    "\n",
    "Hint: you can use [pandas.read_html](https://pandas.pydata.org/docs/reference/api/pandas.read_html.html) to scrape the data into a DataFrame.\n",
    "\n",
    "Steps:\n",
    "1. Create a DataFrame with company tickers, names, and the year they were added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c00db99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "437df753",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "tables = pd.read_html(url)\n",
    "df = tables[0]\n",
    "df = df[['Symbol', 'Security', 'Date added']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8524c6",
   "metadata": {},
   "source": [
    "2. Extract the year from the addition date and calculate the number of stocks added each year.\n",
    "3. Which year had the highest number of additions (1957 doesn't count, as it was the year when the S&P 500 index was founded)? Write down this year as your answer (the most recent one, if you have several records)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f04c885e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year with the most additions (excluding 1957): 2017\n"
     ]
    }
   ],
   "source": [
    "df['Date added'] = pd.to_datetime(df['Date added'], errors='coerce')\n",
    "df['Year added'] = df['Date added'].dt.year\n",
    "additions_per_year = df['Year added'].value_counts().sort_index()\n",
    "filtered = additions_per_year[additions_per_year.index != 1957]\n",
    "max_year = filtered[filtered == filtered.max()].index.max() \n",
    "print(f\"Year with the most additions (excluding 1957): {max_year}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e045251",
   "metadata": {},
   "source": [
    "*Context*: \n",
    "> \"Following the announcement, all four new entrants saw their stock prices rise in extended trading on Friday\" - recent examples of S&P 500 additions include DASH, WSM, EXE, TKO in 2025 ([Nasdaq article](https://www.nasdaq.com/articles/sp-500-reshuffle-dash-tko-expe-wsm-join-worth-buying)).\n",
    "\n",
    "*Additional*: How many current S&P 500 stocks have been in the index for more than 20 years? When stocks are added to the S&P 500, they usually experience a price bump as investors and index funds buy shares following the announcement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a121375a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of current S&P 500 stocks in the index for more than 20 years: 220\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "today = datetime.datetime.today()\n",
    "cutoff_date = today - pd.DateOffset(years=20)\n",
    "df_long_term = df[df['Date added'] <= cutoff_date]\n",
    "num_long_term = df_long_term.shape[0]\n",
    "print(f\"Number of current S&P 500 stocks in the index for more than 20 years: {num_long_term}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23700eca",
   "metadata": {},
   "source": [
    "### Question 2. [Macro] Indexes YTD (as of 1 May 2025)\n",
    "\n",
    "**How many indexes (out of 10) have better year-to-date returns than the US (S&P 500) as of May 1, 2025?**\n",
    "\n",
    "Using Yahoo Finance World Indices data, compare the year-to-date (YTD) performance (1 January-1 May 2025) of major stock market indexes for the following countries:\n",
    "* United States - S&P 500 (^GSPC)\n",
    "* China - Shanghai Composite (000001.SS)\n",
    "* Hong Kong - HANG SENG INDEX (^HSI)\t\n",
    "* Australia - S&P/ASX 200 (^AXJO)\n",
    "* India - Nifty 50 (^NSEI)\n",
    "* Canada - S&P/TSX Composite (^GSPTSE)\n",
    "* Germany - DAX (^GDAXI)\n",
    "* United Kingdom - FTSE 100 (^FTSE)\n",
    "* Japan - Nikkei 225 (^N225)\n",
    "* Mexico - IPC Mexico (^MXX)\n",
    "* Brazil - Ibovespa (^BVSP)\n",
    "\n",
    "*Hint*: use start_date='2025-01-01' and end_date='2025-05-01' when downloading daily data in yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a75abd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t2/44nqhw4n1vd0r1chg2wytynh0000gn/T/ipykernel_21236/2571250671.py:4: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  index_data = yf.download(index_tickers, start=\"2025-01-01\", end=\"2025-05-01\")\n",
      "[*********************100%***********************]  11 of 11 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>000001.SS</th>\n",
       "      <th>^AXJO</th>\n",
       "      <th>^BVSP</th>\n",
       "      <th>^FTSE</th>\n",
       "      <th>^GDAXI</th>\n",
       "      <th>^GSPC</th>\n",
       "      <th>^GSPTSE</th>\n",
       "      <th>^HSI</th>\n",
       "      <th>^MXX</th>\n",
       "      <th>^N225</th>\n",
       "      <th>...</th>\n",
       "      <th>^AXJO</th>\n",
       "      <th>^BVSP</th>\n",
       "      <th>^FTSE</th>\n",
       "      <th>^GDAXI</th>\n",
       "      <th>^GSPC</th>\n",
       "      <th>^GSPTSE</th>\n",
       "      <th>^HSI</th>\n",
       "      <th>^MXX</th>\n",
       "      <th>^N225</th>\n",
       "      <th>^NSEI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-02</th>\n",
       "      <td>3262.561035</td>\n",
       "      <td>8201.200195</td>\n",
       "      <td>120125.0</td>\n",
       "      <td>8260.099609</td>\n",
       "      <td>20024.660156</td>\n",
       "      <td>5868.549805</td>\n",
       "      <td>24898.000000</td>\n",
       "      <td>19623.320312</td>\n",
       "      <td>49765.199219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>304400.0</td>\n",
       "      <td>9373600.0</td>\n",
       "      <td>4.222199e+08</td>\n",
       "      <td>52445600.0</td>\n",
       "      <td>3.621680e+09</td>\n",
       "      <td>215089400.0</td>\n",
       "      <td>4.033400e+09</td>\n",
       "      <td>87535300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>283200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-03</th>\n",
       "      <td>3211.429932</td>\n",
       "      <td>8250.500000</td>\n",
       "      <td>118533.0</td>\n",
       "      <td>8224.000000</td>\n",
       "      <td>19906.080078</td>\n",
       "      <td>5942.470215</td>\n",
       "      <td>25073.500000</td>\n",
       "      <td>19760.269531</td>\n",
       "      <td>48957.238281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>329100.0</td>\n",
       "      <td>9804400.0</td>\n",
       "      <td>7.425039e+08</td>\n",
       "      <td>44372900.0</td>\n",
       "      <td>3.667340e+09</td>\n",
       "      <td>186569100.0</td>\n",
       "      <td>3.393800e+09</td>\n",
       "      <td>112782300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>312300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-06</th>\n",
       "      <td>3206.923096</td>\n",
       "      <td>8288.500000</td>\n",
       "      <td>120022.0</td>\n",
       "      <td>8249.700195</td>\n",
       "      <td>20216.189453</td>\n",
       "      <td>5975.379883</td>\n",
       "      <td>24999.800781</td>\n",
       "      <td>19688.289062</td>\n",
       "      <td>49493.558594</td>\n",
       "      <td>39307.050781</td>\n",
       "      <td>...</td>\n",
       "      <td>52200.0</td>\n",
       "      <td>9685600.0</td>\n",
       "      <td>7.662447e+08</td>\n",
       "      <td>70784900.0</td>\n",
       "      <td>4.940120e+09</td>\n",
       "      <td>239976800.0</td>\n",
       "      <td>2.465700e+09</td>\n",
       "      <td>139872100.0</td>\n",
       "      <td>137900000.0</td>\n",
       "      <td>278100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-07</th>\n",
       "      <td>3229.644043</td>\n",
       "      <td>8285.099609</td>\n",
       "      <td>121163.0</td>\n",
       "      <td>8245.299805</td>\n",
       "      <td>20340.570312</td>\n",
       "      <td>5909.029785</td>\n",
       "      <td>24929.900391</td>\n",
       "      <td>19447.580078</td>\n",
       "      <td>50085.500000</td>\n",
       "      <td>40083.300781</td>\n",
       "      <td>...</td>\n",
       "      <td>424300.0</td>\n",
       "      <td>11116400.0</td>\n",
       "      <td>7.415068e+08</td>\n",
       "      <td>62020000.0</td>\n",
       "      <td>4.517330e+09</td>\n",
       "      <td>237759800.0</td>\n",
       "      <td>3.581000e+09</td>\n",
       "      <td>142173400.0</td>\n",
       "      <td>127000000.0</td>\n",
       "      <td>262300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-24</th>\n",
       "      <td>3297.288086</td>\n",
       "      <td>7968.200195</td>\n",
       "      <td>134580.0</td>\n",
       "      <td>8407.400391</td>\n",
       "      <td>22064.509766</td>\n",
       "      <td>5484.770020</td>\n",
       "      <td>24727.500000</td>\n",
       "      <td>21909.759766</td>\n",
       "      <td>56382.000000</td>\n",
       "      <td>35039.148438</td>\n",
       "      <td>...</td>\n",
       "      <td>639100.0</td>\n",
       "      <td>14113400.0</td>\n",
       "      <td>1.126606e+09</td>\n",
       "      <td>62636800.0</td>\n",
       "      <td>4.697710e+09</td>\n",
       "      <td>224419200.0</td>\n",
       "      <td>2.985800e+09</td>\n",
       "      <td>249950000.0</td>\n",
       "      <td>137100000.0</td>\n",
       "      <td>358800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-25</th>\n",
       "      <td>3295.060059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>134739.0</td>\n",
       "      <td>8415.299805</td>\n",
       "      <td>22242.449219</td>\n",
       "      <td>5525.209961</td>\n",
       "      <td>24710.500000</td>\n",
       "      <td>21980.740234</td>\n",
       "      <td>56720.121094</td>\n",
       "      <td>35705.738281</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13051800.0</td>\n",
       "      <td>8.027340e+08</td>\n",
       "      <td>70917400.0</td>\n",
       "      <td>4.236580e+09</td>\n",
       "      <td>214234300.0</td>\n",
       "      <td>3.025700e+09</td>\n",
       "      <td>217532100.0</td>\n",
       "      <td>134700000.0</td>\n",
       "      <td>387700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-28</th>\n",
       "      <td>3288.415039</td>\n",
       "      <td>7997.100098</td>\n",
       "      <td>135016.0</td>\n",
       "      <td>8417.299805</td>\n",
       "      <td>22271.669922</td>\n",
       "      <td>5528.750000</td>\n",
       "      <td>24798.599609</td>\n",
       "      <td>21971.960938</td>\n",
       "      <td>56980.128906</td>\n",
       "      <td>35839.988281</td>\n",
       "      <td>...</td>\n",
       "      <td>769000.0</td>\n",
       "      <td>11449700.0</td>\n",
       "      <td>7.387417e+08</td>\n",
       "      <td>55883200.0</td>\n",
       "      <td>4.257880e+09</td>\n",
       "      <td>224287200.0</td>\n",
       "      <td>2.466000e+09</td>\n",
       "      <td>193000200.0</td>\n",
       "      <td>132400000.0</td>\n",
       "      <td>320500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-29</th>\n",
       "      <td>3286.655029</td>\n",
       "      <td>8070.600098</td>\n",
       "      <td>135093.0</td>\n",
       "      <td>8463.500000</td>\n",
       "      <td>22425.830078</td>\n",
       "      <td>5560.830078</td>\n",
       "      <td>24874.500000</td>\n",
       "      <td>22008.109375</td>\n",
       "      <td>55613.429688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>710800.0</td>\n",
       "      <td>12761100.0</td>\n",
       "      <td>6.559248e+08</td>\n",
       "      <td>75547100.0</td>\n",
       "      <td>4.747150e+09</td>\n",
       "      <td>199905200.0</td>\n",
       "      <td>3.045200e+09</td>\n",
       "      <td>240938000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>357600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-30</th>\n",
       "      <td>3279.031006</td>\n",
       "      <td>8126.200195</td>\n",
       "      <td>135067.0</td>\n",
       "      <td>8494.900391</td>\n",
       "      <td>22496.980469</td>\n",
       "      <td>5569.060059</td>\n",
       "      <td>24841.699219</td>\n",
       "      <td>22119.410156</td>\n",
       "      <td>56259.281250</td>\n",
       "      <td>36045.378906</td>\n",
       "      <td>...</td>\n",
       "      <td>889500.0</td>\n",
       "      <td>15452400.0</td>\n",
       "      <td>1.589592e+09</td>\n",
       "      <td>99189800.0</td>\n",
       "      <td>5.449490e+09</td>\n",
       "      <td>271264200.0</td>\n",
       "      <td>4.682300e+09</td>\n",
       "      <td>226957400.0</td>\n",
       "      <td>167100000.0</td>\n",
       "      <td>424500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price             Close                                                    \\\n",
       "Ticker        000001.SS        ^AXJO     ^BVSP        ^FTSE        ^GDAXI   \n",
       "Date                                                                        \n",
       "2025-01-01          NaN          NaN       NaN          NaN           NaN   \n",
       "2025-01-02  3262.561035  8201.200195  120125.0  8260.099609  20024.660156   \n",
       "2025-01-03  3211.429932  8250.500000  118533.0  8224.000000  19906.080078   \n",
       "2025-01-06  3206.923096  8288.500000  120022.0  8249.700195  20216.189453   \n",
       "2025-01-07  3229.644043  8285.099609  121163.0  8245.299805  20340.570312   \n",
       "...                 ...          ...       ...          ...           ...   \n",
       "2025-04-24  3297.288086  7968.200195  134580.0  8407.400391  22064.509766   \n",
       "2025-04-25  3295.060059          NaN  134739.0  8415.299805  22242.449219   \n",
       "2025-04-28  3288.415039  7997.100098  135016.0  8417.299805  22271.669922   \n",
       "2025-04-29  3286.655029  8070.600098  135093.0  8463.500000  22425.830078   \n",
       "2025-04-30  3279.031006  8126.200195  135067.0  8494.900391  22496.980469   \n",
       "\n",
       "Price                                                              \\\n",
       "Ticker            ^GSPC       ^GSPTSE          ^HSI          ^MXX   \n",
       "Date                                                                \n",
       "2025-01-01          NaN           NaN           NaN           NaN   \n",
       "2025-01-02  5868.549805  24898.000000  19623.320312  49765.199219   \n",
       "2025-01-03  5942.470215  25073.500000  19760.269531  48957.238281   \n",
       "2025-01-06  5975.379883  24999.800781  19688.289062  49493.558594   \n",
       "2025-01-07  5909.029785  24929.900391  19447.580078  50085.500000   \n",
       "...                 ...           ...           ...           ...   \n",
       "2025-04-24  5484.770020  24727.500000  21909.759766  56382.000000   \n",
       "2025-04-25  5525.209961  24710.500000  21980.740234  56720.121094   \n",
       "2025-04-28  5528.750000  24798.599609  21971.960938  56980.128906   \n",
       "2025-04-29  5560.830078  24874.500000  22008.109375  55613.429688   \n",
       "2025-04-30  5569.060059  24841.699219  22119.410156  56259.281250   \n",
       "\n",
       "Price                     ...    Volume                                        \\\n",
       "Ticker             ^N225  ...     ^AXJO       ^BVSP         ^FTSE      ^GDAXI   \n",
       "Date                      ...                                                   \n",
       "2025-01-01           NaN  ...       NaN         NaN           NaN         NaN   \n",
       "2025-01-02           NaN  ...  304400.0   9373600.0  4.222199e+08  52445600.0   \n",
       "2025-01-03           NaN  ...  329100.0   9804400.0  7.425039e+08  44372900.0   \n",
       "2025-01-06  39307.050781  ...   52200.0   9685600.0  7.662447e+08  70784900.0   \n",
       "2025-01-07  40083.300781  ...  424300.0  11116400.0  7.415068e+08  62020000.0   \n",
       "...                  ...  ...       ...         ...           ...         ...   \n",
       "2025-04-24  35039.148438  ...  639100.0  14113400.0  1.126606e+09  62636800.0   \n",
       "2025-04-25  35705.738281  ...       NaN  13051800.0  8.027340e+08  70917400.0   \n",
       "2025-04-28  35839.988281  ...  769000.0  11449700.0  7.387417e+08  55883200.0   \n",
       "2025-04-29           NaN  ...  710800.0  12761100.0  6.559248e+08  75547100.0   \n",
       "2025-04-30  36045.378906  ...  889500.0  15452400.0  1.589592e+09  99189800.0   \n",
       "\n",
       "Price                                                                          \\\n",
       "Ticker             ^GSPC      ^GSPTSE          ^HSI         ^MXX        ^N225   \n",
       "Date                                                                            \n",
       "2025-01-01           NaN          NaN           NaN          NaN          NaN   \n",
       "2025-01-02  3.621680e+09  215089400.0  4.033400e+09   87535300.0          NaN   \n",
       "2025-01-03  3.667340e+09  186569100.0  3.393800e+09  112782300.0          NaN   \n",
       "2025-01-06  4.940120e+09  239976800.0  2.465700e+09  139872100.0  137900000.0   \n",
       "2025-01-07  4.517330e+09  237759800.0  3.581000e+09  142173400.0  127000000.0   \n",
       "...                  ...          ...           ...          ...          ...   \n",
       "2025-04-24  4.697710e+09  224419200.0  2.985800e+09  249950000.0  137100000.0   \n",
       "2025-04-25  4.236580e+09  214234300.0  3.025700e+09  217532100.0  134700000.0   \n",
       "2025-04-28  4.257880e+09  224287200.0  2.466000e+09  193000200.0  132400000.0   \n",
       "2025-04-29  4.747150e+09  199905200.0  3.045200e+09  240938000.0          NaN   \n",
       "2025-04-30  5.449490e+09  271264200.0  4.682300e+09  226957400.0  167100000.0   \n",
       "\n",
       "Price                 \n",
       "Ticker         ^NSEI  \n",
       "Date                  \n",
       "2025-01-01  154900.0  \n",
       "2025-01-02  283200.0  \n",
       "2025-01-03  312300.0  \n",
       "2025-01-06  278100.0  \n",
       "2025-01-07  262300.0  \n",
       "...              ...  \n",
       "2025-04-24  358800.0  \n",
       "2025-04-25  387700.0  \n",
       "2025-04-28  320500.0  \n",
       "2025-04-29  357600.0  \n",
       "2025-04-30  424500.0  \n",
       "\n",
       "[86 rows x 55 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "index_tickers = [\"^GSPC\", \"000001.SS\", \"^HSI\", \"^AXJO\", \"^NSEI\", \"^GSPTSE\", \"^GDAXI\", \"^FTSE\", \"^N225\", \"^MXX\", \"^BVSP\"]\n",
    "index_data = yf.download(index_tickers, start=\"2025-01-01\", end=\"2025-05-01\")\n",
    "index_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ca1c5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of indexes with better YTD performance than the US (S&P 500): 9 out of 10\n"
     ]
    }
   ],
   "source": [
    "close_prices = index_data['Close']\n",
    "close_prices = close_prices.dropna()\n",
    "start_prices = close_prices.iloc[0]\n",
    "end_prices = close_prices.iloc[-1]\n",
    "returns = ((end_prices - start_prices) / start_prices) * 100\n",
    "sp500_return = returns[\"^GSPC\"]\n",
    "better_than_us = (returns > sp500_return).sum()\n",
    "print(f\"Number of indexes with better YTD performance than the US (S&P 500): {better_than_us} out of {len(returns)-1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00ba805",
   "metadata": {},
   "source": [
    "### Question 3. [Index] S&P 500 Market Corrections Analysis\n",
    "\n",
    "\n",
    "**Calculate the median duration (in days) of significant market corrections in the S&P 500 index.**\n",
    "\n",
    "For this task, define a correction as an event when a stock index goes down by **more than 5%** from the closest all-time high maximum.\n",
    "\n",
    "Steps:\n",
    "1. Download S&P 500 historical data (1950-present) using yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d499c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t2/44nqhw4n1vd0r1chg2wytynh0000gn/T/ipykernel_21236/1659991059.py:1: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  sp_500 = yf.download('^GSPC', start='1950-01-01')['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "sp_500 = yf.download('^GSPC', start='1950-01-01')['Close']\n",
    "sp_500 = sp_500['^GSPC'].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca348d3",
   "metadata": {},
   "source": [
    "2. Identify all-time high points (where price exceeds all previous prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48ef3d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_time_highs = sp_500.cummax()\n",
    "high_dates = sp_500[sp_500 == all_time_highs].index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a8c489",
   "metadata": {},
   "source": [
    "3. For each pair of consecutive all-time highs, find the minimum price in between\n",
    "4. Calculate drawdown percentages: (high - low) / high × 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37b8b734",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections = []\n",
    "\n",
    "for i in range(len(high_dates) - 1):\n",
    "    start_date = high_dates[i]\n",
    "    end_date = high_dates[i + 1]\n",
    "    high_value = sp_500.loc[start_date]\n",
    "\n",
    "    # Buscar el precio mínimo entre dos máximos\n",
    "    low_between = sp_500.loc[start_date:end_date].min()\n",
    "    low_date = sp_500.loc[start_date:end_date].idxmin()\n",
    "\n",
    "    drawdown = (high_value - low_between) / high_value * 100\n",
    "\n",
    "    if drawdown >= 5:\n",
    "        duration = (low_date - start_date).days\n",
    "        corrections.append(duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752da87a",
   "metadata": {},
   "source": [
    "5. Filter for corrections with at least 5% drawdown\n",
    "6. Calculate the duration in days for each correction period\n",
    "7. Determine the 25th, 50th (median), and 75th percentiles for correction durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b38beaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correction Duration Percentiles (in days):\n",
      "25th percentile: 21 days\n",
      "Median (50th): 39 days\n",
      "75th percentile: 89 days\n"
     ]
    }
   ],
   "source": [
    "corrections_series = pd.Series(corrections)\n",
    "percentiles = corrections_series.quantile([0.25, 0.5, 0.75]).astype(int)\n",
    "\n",
    "print(\"Correction Duration Percentiles (in days):\")\n",
    "print(f\"25th percentile: {percentiles[0.25]} days\")\n",
    "print(f\"Median (50th): {percentiles[0.5]} days\")\n",
    "print(f\"75th percentile: {percentiles[0.75]} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73820ebb",
   "metadata": {},
   "source": [
    "### Question 4.  [Stocks] Earnings Surprise Analysis for Amazon (AMZN)\n",
    "\n",
    "\n",
    "**Calculate the median 2-day percentage change in stock prices following positive earnings surprises days.**\n",
    "\n",
    "Steps:\n",
    "1. Load earnings data from CSV ([ha1_Amazon.csv](ha1_Amazon.csv)) containing earnings dates, EPS estimates, and actual EPS. Make sure you are using the correct delimiter to read the data, such as in this command ```python pandas.read_csv(\"ha1_Amazon.csv\", delimiter=';') ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eaa0d667",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = pd.read_csv('https://raw.githubusercontent.com/DataTalksClub/stock-markets-analytics-zoomcamp/refs/heads/main/cohorts/2025/ha1_Amazon.csv', sep=';').iloc[:-1, :]\n",
    "df_4['Earnings Date'] = pd.to_datetime(df_4['Earnings Date'].str.split(' at').str[0], errors='coerce')\n",
    "numeric_cols = ['EPS Estimate', 'Reported EPS', 'Surprise (%)']\n",
    "for col in numeric_cols:\n",
    "    df_4[col] = pd.to_numeric(df_4[col].str.replace('[^-.0-9]', '', regex=True), errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8ce1f3",
   "metadata": {},
   "source": [
    "2. Download complete historical price data using yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "914ab6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t2/44nqhw4n1vd0r1chg2wytynh0000gn/T/ipykernel_21236/2886282018.py:1: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  amzn = yf.download('AMZN', start='1997-05-15')['Close'].reset_index()\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "amzn = yf.download('AMZN', start='1997-05-15')['Close'].reset_index()\n",
    "amzn.columns = ['Date', 'Price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15d3bd2",
   "metadata": {},
   "source": [
    "3. Calculate 2-day percentage changes for all historical dates: for each sequence of 3 consecutive trading days (Day 1, Day 2, Day 3), compute the *return* as Close_Day3 / Close_Day1 - 1. (Assume Day 2 may correspond to the earnings announcement.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eed6fca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn['2_day_pct_change'] =((amzn['Price'].shift(-2) / amzn['Price']) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b30ce6a",
   "metadata": {},
   "source": [
    "4. Identify positive earnings surprises (where \"actual EPS > estimated EPS\"). Both fields should be present in the file. You should obtain 36 data points for use in the descriptive analysis (median) later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8ab963bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_surprises = df_4[(df_4['Reported EPS'] > df_4['EPS Estimate']) | (df_4['Surprise (%)'] > 0)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e25da2",
   "metadata": {},
   "source": [
    "5. Calculate 2-day percentage changes following positive earnings surprises. Show your answer in % (closest number to the 2nd digit): *return* * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "41125650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2672266474036067"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_to_consider = positive_surprises['Earnings Date'].tolist()\n",
    "amzn_filtered = amzn[amzn['Date'].isin(dates_to_consider)].copy()\n",
    "amzn_filtered['2_day_pct_change'].median()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "67d26caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.002672266474036067, 0.0016581674487468057)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.merge_asof(\n",
    "    df_4.sort_values('Earnings Date'),\n",
    "    amzn.sort_values('Date'),\n",
    "    left_on='Earnings Date',\n",
    "    right_on='Date',\n",
    "    direction='forward'\n",
    ")\n",
    "\n",
    "positive_surprises = merged[\n",
    "    ((merged['Reported EPS'] > merged['EPS Estimate']) | (merged['Surprise (%)'] > 0)) &\n",
    "    merged['2_day_pct_change'].notna()\n",
    "].copy()\n",
    "\n",
    "median_positive = positive_surprises['2_day_pct_change'].median()\n",
    "median_all = amzn['2_day_pct_change'].median()\n",
    "\n",
    "median_positive, median_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1946536f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
